\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09
\newcommand\BibTeX{B{\sc ib}\TeX}

\title{LSTM for Sentiment Analysis on Twitter}

\author{
Trapit Bansal
\And
Kate Silverstein
\And
Jun Wang
}

%% \author{
%% David S.~Hippocampus\thanks{ Use footnote for providing further information
%% about author (webpage, alternative address)---\emph{not} for acknowledging
%% funding agencies.} \\
%% Department of Computer Science\\
%% Cranberry-Lemon University\\
%% Pittsburgh, PA 15213 \\
%% \texttt{hippo@cs.cranberry-lemon.edu} \\
%% \And
%% Coauthor \\
%% Affiliation \\
%% Address \\
%% \texttt{email} \\
%% \AND
%% Coauthor \\
%% Affiliation \\
%% Address \\
%% \texttt{email} \\
%% \And
%% Coauthor \\
%% Affiliation \\
%% Address \\
%% \texttt{email} \\
%% \And
%% Coauthor \\
%% Affiliation \\
%% Address \\
%% \texttt{email} \\
%% (if needed)\\
%% }


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
abstract goes here
\end{abstract}

\section{Introduction}
% why analysis sentiment expecially twitter
In the last fewer year, microblogging has become a very popular communication tool in people's social life.
On microblogging platforms, such as Twitter\footnote{\url{https://twitter.com/}} and Facebook\footnote{\url{https://www.facebook.com/}}, a diverge range of people are attracted to post short sentences, images, and video links to share life issues and opinions.
This popularity results in enormous amount of information coving a wide range of topics from celebrities to opinions about the brands, products, politicians and social events. 
Such data is a valuable and efficient source for marketing and social studies, and therefore sentiment analysis on these data have obtained special interest. 
For example, manufacturing companies may want to know how people like their product (or service), what would people prefer.

We restrict our interest on Twitter sentiment analysis for following reasons: 
People are posting on various topics on Twitter, thus it is a valuable source of data; Twitter is one of most popular microblogging platform and the number of messages are growing everyday. The collected corp can be arbitrary large; Users of Twitter have various background and have different language conventions It is possible to collect tweets of large diversity in both topics and language model.
%Some typical examples of tweets are shown in Table \ref{tweet-example}. 
%
%\begin{table}[h]
%	\caption{Examples of typical tweets}
%	\label{tweet-example}
%	\begin{center}
%		\begin{tabular}{l}
%			\hline
%			Edelman11 Cant. Wait. \#TheForceAwakens \#starpats \\\hline
%			JeriLRyan SQUEEEEEEEEEE!!!!! Thank you, @Sphero!!! (And @bonniegrrl, you rock!!)   \\\hline
%			@appcompany Why haven’t you updated your app? Apple released a new iOS and your app now doesn’t work.\\ \hline
%		\end{tabular}
%	\end{center}
%\end{table}

Compared with traditional blogs, tweets have some unique characteristics: 1. Tweets are short in length. There is a limitation of $140$ words for each tweet; 2. The language used in tweets is very information with misspelling, creative spelling,  new words, slang, and URLs; 3. Emoticons and hashtags are frequently used.

% what we did
In this paper, we propose a bi-direction LSTM (Long Short -Term Memory)\cite{hochreiter1997long} method for sentiment analysis. We tried both word-level and character-level features on the bi-direction LSTM model and compare the results with DCNN (Dynamic Convolutional Neural Network) \cite{kalchbrenner2014convolutional}.
We show that the accuracy of sentiment analysis ... (Please revise this part.)

We train our model on $1.6$M distantly-supervised tweets collected by Go et. al. \cite{go2009twitter}, and evaluate the result on SemEval-2016 Task 4. Currently we focus on polarity classification, and plan to apply our model on 5-point scale classification in the future. 

% the structure of the paper
In the remaining of this paper, we first introduce the related work, the dataset, and the evaluation methodology. We then describe the model we proposed. Finally, we discuss the experiment results and point to possible directions for future research. (Please revise this part.)

\section{Related Work}
Twitter sentiment analysis is increasingly drawing attention of researchers in recent years. 
Given the length limitations on tweets, sentiment analysis of tweets is often considered similar to sentence-level sentiment analysis \cite{kouloumpis2011twitter}.
However, phrase and sentence level approaches can hardly define the sentiment of some specific topic. Considering opinions adhering on different topics, Wang et. al.\cite{wang2011topic} proposed a hashtag-level sentiment classification method  to generate the overall sentiment polarity for a given hashtag.
Recently, following the work of \cite{mikolov2013efficient} some researchers employed neural network to implement sentiment classification. 
For example, Kim \cite{kim2014convolutional} adopted convolutional neural networks to learn sentiment-bearing sentence vectors, Mikolov et al.\cite{mikolov2013distributed} proposed Paragraph vector which outperformed bag-of-words model for sentiment analysis, and Tang et. al. \cite{tang2014learning} used ConvNets to learn sentiment specific word embedding (SSWE), which encodes sentiment information in the continuous
representation of words.
Furthermore, Kalchbrenner \cite{kalchbrenner2014convolutional} proposed a Dynamic Convolutional Neural Network (DCNN) which uses dynamic k-max pooling, a global pooling operation over linear sequences.
Instead of directly applying ConvNets to embeddings of words, \cite{zhang2015character} apply the network only on characters. They showed that the deep ConvNets do not require knowledge of words and thus can work for different languages.


\section{Model}

\section{Experiments}
See Table ~\ref{sample-table} for awesome results

\begin{table}[h]
\caption{Sample table title}
\label{sample-table}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
\\ \hline \\
Dendrite         &Input terminal \\
Axon             &Output terminal \\
Soma             &Cell body (contains cell nucleus) \\
\end{tabular}
\end{center}
\end{table}

This is a figure:

\begin{figure}[h]
\begin{center}
%\framebox[4.0in]{$\;$}
\fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
\end{center}
\caption{Sample figure caption.}
\end{figure}

\section{Conclusion}


\subsubsection*{Acknowledgments}



\subsubsection*{References}

\bibliography{paper}
\bibliographystyle{plain}
%% References follow the acknowledgments. Use unnumbered third level heading for
%% the references. Any choice of citation style is acceptable as long as you are
%% consistent. It is permissible to reduce the font size to `small' (9-point) 
%% when listing the references. {\bf Remember that this year you can use
%% a ninth page as long as it contains \emph{only} cited references.}

%% \small{
%% [1] Alexander, J.A. \& Mozer, M.C. (1995) Template-based algorithms
%% for connectionist rule extraction. In G. Tesauro, D. S. Touretzky
%% and T.K. Leen (eds.), {\it Advances in Neural Information Processing
%% Systems 7}, pp. 609-616. Cambridge, MA: MIT Press.

%% [2] Bower, J.M. \& Beeman, D. (1995) {\it The Book of GENESIS: Exploring
%% Realistic Neural Models with the GEneral NEural SImulation System.}
%% New York: TELOS/Springer-Verlag.

%% [3] Hasselmo, M.E., Schnell, E. \& Barkai, E. (1995) Dynamics of learning
%% and recall at excitatory recurrent synapses and cholinergic modulation
%% in rat hippocampal region CA3. {\it Journal of Neuroscience}
%% {\bf 15}(7):5249-5262.
%% }

\end{document}
